{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>ZincSearch is a full-text search server implemented in Go language, providing an API compatible with ElasticSearch DSL. It uses Bluge as the indexing engine. Bluge is a fork version of Bleve (developed by CouchBase), a widely used Go language full-text indexing library, which refactors the code to make it more modern and flexible.</p>"},{"location":"api/seasearch_api/","title":"API introduction","text":"<p>SeaSearch uses Http Basic Auth for permission verification, and the API request needs to carry the corresponding token in the header.</p> <p>Generate basic auth through this tool: http://web.chacuo.net/safebasicauth</p>"},{"location":"api/seasearch_api/#user-management","title":"User management","text":""},{"location":"api/seasearch_api/#administrator-user","title":"Administrator user","text":"<p>SeaSearch manages API permissions through accounts. When the program is started for the first time, an administrator account needs to be configured through environment variables.</p> <p>The following is an example of an administrator account:</p> <pre><code>set ZINC_FIRST_ADMIN_USER=admin\nset ZINC_FIRST_ADMIN_PASSWORD=xxx\n</code></pre>"},{"location":"api/seasearch_api/#normal-user","title":"Normal user","text":"<p>Users can be created/updated via the API:</p> <pre><code>[POST] /api/user\n\n{ \n    \"_id\": \"prabhat\",\n    \"name\": \"Prabhat Sharma\",\n    \"role\": \"admin\", // or user\n    \"password\": \"xxx\"\n}\n</code></pre> <p>get all users\uff1a</p> <pre><code>[GET] /api/user\n</code></pre> <p>delete user\uff1a</p> <pre><code>[DELETE] /api/user/${userId}\n</code></pre>"},{"location":"api/seasearch_api/#index-related","title":"Index related","text":""},{"location":"api/seasearch_api/#create-index","title":"create index","text":"<p>Create a SeaSearch index, and you can set both mappings and settings at the same time.</p> <p>We can also set settings or mapping directly through other requests. If the index does not exist, it will be created automatically.</p> <p>SeaSearch documentation\uff1ahttps://zincsearch-docs.zinc.dev/api/index/create/#update-a-exists-index</p> <p>ES documentation\uff1ahttps://www.elastic.co/guide/en/elasticsearch/reference/current/indices-create-index.html</p>"},{"location":"api/seasearch_api/#configure-mappings","title":"Configure mappings","text":"<p>Mappings define the rules for fields in a document, such as type, format, etc.</p> <p>Mapping can be configured via a separate API:</p> <p>SeaSearch api: https://zincsearch-docs.zinc.dev/api-es-compatible/index/update-mapping/</p> <p>ES related instructions\uff1ahttps://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-types.html</p>"},{"location":"api/seasearch_api/#configure-settings","title":"Configure settings","text":"<p>Settings set the analyzer sharding and other related settings of the index.</p> <p>SeaSearch api: https://zincsearch-docs.zinc.dev/api-es-compatible/index/update-settings/</p> <p>ES related instructions\uff1a</p> <ul> <li> <p>analyzer related concepts\uff1ahttps://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-concepts.html</p> </li> <li> <p>How to specify an analyzer\uff1ahttps://www.elastic.co/guide/en/elasticsearch/reference/current/specify-analyzer.html</p> </li> </ul>"},{"location":"api/seasearch_api/#analyzer-support","title":"Analyzer support","text":"<p>Analyzer can configure the default when creating an index, or set it for a specific field. (Refer to the settings ES documentation in the previous section to understand the relevant concepts.)</p> <p>The analyzers supported by SeaSearch can be found on this page: https://zincsearch-docs.zinc.dev/api/index/analyze/. The concepts such as tokenize and token filter are consistent with ES, and most of the commonly used analyzers and tokenizers in ES are supported.</p> <p>Supported general analyzers</p> <ul> <li> <p>standard, the default analyzer. If not specified, this analyzer is used to split words and lowercase them.</p> </li> <li> <p>simple, split according to non-letters (symbols are filtered), lowercase</p> </li> <li> <p>keyword, no word segmentation, directly treat input as output</p> </li> <li> <p>stop, lowercase, stop word filter (the, a, is, etc.)</p> </li> <li> <p>web, implemented by Bluge, matching email addresses, urls, etc. Handling lowercase, using stop word filters</p> </li> <li> <p>regexp/pattern, regular expression, default is \\W+ (non-character segmentation), supports lowercase and stop words</p> </li> <li> <p>whitespace, split by space, do not convert to lowercase</p> </li> </ul>"},{"location":"api/seasearch_api/#luanguages-analyzers","title":"Luanguages analyzers","text":"Country Shortened form arabic ar Asia Countries cjk sorani ckb danish da german de english en spanish es persian fa finnish fi french fr hindi hi hungarian hu italian it dutch nl norwegian no portuguese pt romanian ro russian ru swedish sv turkish tr <p>Chinese analyzer:</p> <ul> <li> <p>gse_standard, use the shortest path algorithm to segment words</p> </li> <li> <p>gse_search, the search engine's word segmentation mode provides as many keywords as possible</p> </li> </ul> <p>The Chinese analyzer uses the gse library to implement word segmentation. It is a Golang implementation of the Python stammer library. It is not enabled by default and needs to be enabled through environment variables.</p> <pre><code>ZINC_PLUGIN_GSE_ENABLE=true\n# true: enable Chinese word segmentation support, default is false\n\nZINC_PLUGIN_GSE_DICT_EMBED=BIG \n# BIG: use the gse built-in vocabulary and stop words; otherwise, use the SeaSearch built-in simple vocabulary, the default is small\n\nZINC_PLUGIN_GSE_ENABLE_STOP=true\n# true: use stop words, default true\n\nZINC_PLUGIN_GSE_ENABLE_HMM=true\n# Use HMM mode for search word segmentation, default is true\n\nZINC_PLUGIN_GSE_DICT_PATH=./plugins/gse/dict\n# To use a user-defined word library and stop words, you need to put the content in the configured path, and name the word library user.txt and the stop words stop.txt\n</code></pre>"},{"location":"api/seasearch_api/#full-text-search","title":"Full text search","text":""},{"location":"api/seasearch_api/#document-crud","title":"document CRUD","text":"<p>create document:</p> <p>SeaSearch API: https://zincsearch-docs.zinc.dev/api-es-compatible/document/create/</p> <p>ES API\uff1ahttps://www.elastic.co/guide/en/elasticsearch/reference/current/docs-index_.html</p> <p>update document:</p> <p>SeaSearch API: https://zincsearch-docs.zinc.dev/api-es-compatible/document/update/</p> <p>ES API: https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-update.html</p> <p>delete document\uff1a</p> <p>SeaSearch API: https://zincsearch-docs.zinc.dev/api-es-compatible/document/delete/</p> <p>ES API: https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-delete.html</p> <p>Get document by id:</p> <pre><code>[GET] /api/${indexName}/_doc/${docId}\n</code></pre>"},{"location":"api/seasearch_api/#batch-operation","title":"Batch Operation","text":"<p>Batch operations should be used to update indexes whenever possible.</p> <p>SeaSearch API\uff1a https://zincsearch-docs.zinc.dev/api-es-compatible/document/bulk/#request</p> <p>ES API\uff1ahttps://www.elastic.co/guide/en/elasticsearch/reference/current/docs-bulk.html</p>"},{"location":"api/seasearch_api/#search","title":"search","text":"<p>API examples:</p> <p>https://zincsearch-docs.zinc.dev/api-es-compatible/search/search/</p> <p>Full-text search uses DSL. For usage, please refer to:</p> <p>https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html</p> <p>delete-by-query\uff1aDelete based on query</p> <pre><code>[POST] /es/${indexName}/_delete_by_query\n\n{\n  \"query\": {\n    \"match\": {\n      \"name\": \"jack\"\n    }\n  }\n}\n</code></pre> <p>ES API: https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-delete-by-query.html</p> <p>multi-search\uff0csupports executing different queries on different indexes:</p> <p>SeaSearch API: https://zincsearch-docs.zinc.dev/api-es-compatible/search/msearch/</p> <p>ES API: https://www.elastic.co/guide/en/elasticsearch/reference/current/search-multi-search.html</p> <p>We have extended multi-search to support using the same statistics when searching different indexes to make the score calculation more accurate. You can enable it by setting query: unify_score=true in the request.</p> <pre><code>[POST] /es/_msearch?unify_score=true\n\n{\"index\": \"t1\"}\n{\"query\": {\"bool\": {\"should\": [{\"match\": {\"filename\": {\"query\": \"test string\", \"minimum_should_match\": \"-25%\"}}}, {\"match\": {\"filename.ngram\": {\"query\": \"test string\", \"minimum_should_match\": \"80%\"}}}], \"minimum_should_match\": 1}}, \"from\": 0, \"size\": 10, \"_source\": [\"path\", \"repo_id\", \"filename\", \"is_dir\"], \"sort\": [\"_score\"]}\n{\"index\": \"t2\"}\n{\"query\": {\"bool\": {\"should\": [{\"match\": {\"filename\": {\"query\": \"test string\", \"minimum_should_match\": \"-25%\"}}}, {\"match\": {\"filename.ngram\": {\"query\": \"test string\", \"minimum_should_match\": \"80%\"}}}], \"minimum_should_match\": 1}}, \"from\": 0, \"size\": 10, \"_source\": [\"path\", \"repo_id\", \"filename\", \"is_dir\"], \"sort\": [\"_score\"]}\n</code></pre>"},{"location":"api/seasearch_api/#vector-search","title":"Vector search","text":"<p>We have developed a vector search function for the SeaSearch extension. The following is an introduction to the relevant API.</p>"},{"location":"api/seasearch_api/#create-vector-search","title":"Create vector search","text":"<p>To use the vector search function, you need to create a vector index in advance, which can be done through mapping.</p> <p>We create an index and set the vector field of the document data to be written to be called \"vec\", the index type is flat, and the vector dimension is 768</p> <pre><code>[PUT] /es/${indexName}/_mapping\n\n{\n\"properties\":{\n        \"vec\":{\n            \"type\":\"vector\", \n            \"dims\":768,\n            \"m\":64,\n            \"nbits\":8,\n            \"vec_index_type\":\"flat\"\n        }\n    }\n}\n</code></pre> <p>Parameter Description:</p> <pre><code>${indexName} zincIndex, index name\n\ntype,  fixed to vector, indicating vector index\ndims,  vector dimensions\nm,     ivf_pq index required parameters, need to be divisible by dims\nnbits, ivf_pq index required parameter, default is 8\nvec_index_type, index type, supports two types: flat and ivf_pq\n</code></pre>"},{"location":"api/seasearch_api/#write-a-document-containing-a-vector","title":"Write a document containing a vector","text":"<p>There is no difference between writing a document containing a vector and writing a normal document at the API level. You can choose the appropriate method.</p> <p>The following takes the bluk API as an example</p> <pre><code>[POST] /es/_bulk\n\nbody:\n\n{ \"index\" : { \"_index\" : \"index1\" } } \n{\"name\": \"jack1\",\"vec\":[10.2,10.41,9.5,22.2]}\n{ \"index\" : { \"_index\" : \"index1\" } } \n{\"name\": \"jack2\",\"vec\":[10.2,11.41,9.5,22.2]}\n{ \"index\" : { \"_index\" : \"index1\" } } \n{\"name\": \"jack3\",\"vec\":[10.2,12.41,9.5,22.2]}\n</code></pre> <p>Note that the _bulk API strictly requires the format of each line, and the data cannot exceed one line. For details, please refer to ES bulk</p> <p>Modification and deletion can also be done using bulk. After deleting a document, its corresponding vector data will also be deleted</p>"},{"location":"api/seasearch_api/#retrieval-vector","title":"Retrieval vector","text":"<p>By passing in a vector, we can search for N similar vectors in the system and return the corresponding document information:</p> <pre><code>[POST] /api/${indexName}/_search/vector\n\nbody:\n{\n    {\n    \"query_field\":\"vec\",\n    \"k\":7,\n    \"return_fields\":[\"name\"],\n    \"vector\":[10.2,10.40,9.5,22.2.......],\n    \"_source\":false\n    }\n}\n</code></pre> <p>The API response format is the same as the full-text search format.</p> <p>The following is a description of the parameters:</p> <pre><code>${indexName} zincIndex, index name\n\nquery_field,    the field in the index to retrieve, the field must be of vector type\nk,              the number of K most similar vectors to return\nreturn_fields,  the name of the field to be returned individually\nvector,         the vector used for query\nnprobe,         only works for ivf_pq index type, the number of clusters to query, the higher the number, the more accurate\n_source,        it is used to control whether to return the _source field, supports bool or an array, describing which fields need to be returned\n</code></pre>"},{"location":"api/seasearch_api/#rebuild-index","title":"Rebuild index","text":"<p>Rebuild the index immediately, suitable for situations where you don't need to wait for background automatic detection.</p> <pre><code>[POST] /api/:target/:field/_rebuild\n</code></pre>"},{"location":"api/seasearch_api/#query-recall","title":"query recall","text":"<p>For vectors of type ivf_pq, recall checks can be performed on their data.</p> <pre><code>[POST] /api/:target/_recall\n{\n    \"field\":\"vec_001\", # Fields to test\n    \"k\":10, \n    \"nprobe\":5, # nprobe number\n    \"query_count\":1000 # Number of times the test was performed\n}\n</code></pre>"},{"location":"api/seasearch_api/#vector-search-usage-examples","title":"Vector search usage examples","text":"<p>Next, we will demonstrate how to index a batch of papers. Each paper may contain multiple vectors that need to be indexed. We hope to obtain the most similar N vectors through vector retrieval, and thus obtain their corresponding paper-ids.</p>"},{"location":"api/seasearch_api/#creating-seasearch-indexes-and-vector-indexes","title":"Creating SeaSearch indexes and vector indexes","text":"<p>The first step is to set the mapping of the vector index. When setting the mapping, the index and vector index are automatically created.</p> <p>Since paper-id is just a normal string, we don't need to analyze it, so we set its type to keyword:</p> <pre><code>[PUT] /es/paper/_mapping\n\n{\n\"properties\":{\n        \"title-vec\":{\n            \"type\":\"vector\", \n            \"dims\":768,\n            \"vec_index_type\":\"flat\",\n            \"m\":1\n        },\n        \"paper-id\":{\n            \"type\":\"keyword\"\n        }\n    }\n}\n</code></pre> <p>Through the above request, we created an index named paper and established a flat vector index for the title-vec field of the index.</p>"},{"location":"api/seasearch_api/#index-data","title":"Index data","text":"<p>We write these paper data to SeaSearch in batches through the _bulk API.</p> <pre><code>[POST] /es/_bulk\n\n{ \"index\" : {\"_index\" : \"paper\" } } \n{\"paper-id\": \"001\",\"title-vec\":[10.2,10.40,9.5,22.2....]}\n{ \"index\" : {\"_index\" : \"paper\" } } \n{\"paper-id\": \"002\",\"title-vec\":[10.2,11.40,9.5,22.2....]}\n{ \"index\" : {\"_index\" : \"paper\" } } \n{\"paper-id\": \"003\",\"title-vec\":[10.2,12.40,9.5,22.2....]}\n....\n</code></pre>"},{"location":"api/seasearch_api/#retrieving-data","title":"Retrieving data","text":"<p>Now we can retrieve it using the vector:</p> <pre><code>[POST] /api/paper/_search/vector\n\n{\n    \"query_field\":\"title-vec\",\n    \"k\":10,\n    \"return_fields\":[\"paper-id\"],\n    \"vector\":[10.2,10.40,9.5,22.2....]\n}\n</code></pre> <p>The document corresponding to the most similar vector can be retrieved, and the paper-id can be obtained. Since a paper may contain multiple vectors, if multiple vectors of a paper are very similar to the query vector, then this paper-id may appear multiple times in the results.</p>"},{"location":"api/seasearch_api/#maintaining-vector-data","title":"Maintaining vector data","text":""},{"location":"api/seasearch_api/#update-the-document-directly","title":"Update the document directly","text":"<p>After a document is successfully imported, SeaSearch will return its doc id. We can directly update a document based on the doc id:</p> <pre><code>[POST] /es/_bulk\n\n{ \"update\" : {\"_id\":\"23gZX9eT6QM\",\"_index\" : \"paper\" } } \n{\"paper-id\": \"005\",\"vec\":[10.2,1.43,9.5,22.2...]}\n</code></pre>"},{"location":"api/seasearch_api/#query-first-and-then-update","title":"Query first and then update","text":"<p>If the returned doc id is not saved, you can first use SeaSearch's full-text search function to query the documents corresponding to paper-id:</p> <pre><code>[POST] /es/paper/_search\n\n{\n    \"query\": {\n        \"bool\": {\n            \"must\": [\n                {\n                    \"term\": {\"paper-id\":\"003\"}\n                }\n            ]\n        }\n    }\n}\n</code></pre> <p>Through DSL, we can directly retrieve the document corresponding to the paper-id and its doc id.</p>"},{"location":"api/seasearch_api/#fully-updated-paper","title":"Fully updated paper","text":"<p>A paper contains multiple vectors. If a vector needs to be updated, we can directly update the document corresponding to the vector. However, in actual applications, it is not easy to distinguish which contents of a paper are newly added and which are updated.</p> <p>We can adopt the method of full update:</p> <ul> <li> <p>First, query all documents of a paper through DSL</p> </li> <li> <p>Delete all documents</p> </li> <li> <p>Import the latest paper data</p> </li> </ul> <p>Steps 2 and 3 can be performed in one batch operation.</p> <p>The following example will demonstrate deleting the document of paper 001 and re-importing it; at the same time, directly updating paper 005 and paper 006 because they only have one vector:</p> <pre><code>[POST] /es/_bulk\n\n\n{ \"index\" : {\"_index\" : \"paper\" } } \n{\"paper-id\": \"001\",\"title-vec\":[10.2,10.40,9.5,22.2....]}\n{ \"index\" : {\"_index\" : \"paper\" } } \n{\"paper-id\": \"002\",\"title-vec\":[10.2,11.40,9.5,22.2....]}\n{ \"index\" : {\"_index\" : \"paper\" } } \n{\"paper-id\": \"003\",\"title-vec\":[10.2,12.40,9.5,22.2....]}\n....\n</code></pre>"},{"location":"config/","title":"SeaSearch Configuration","text":""},{"location":"config/#original-configurations","title":"Original Configurations","text":"<p>The original configurations of environment variables can be referenced\uff1ahttps://zincsearch-docs.zinc.dev/environment-variables/</p> <p>The following configuration instructions are for our extended configuration items. All configurations are set in the form of environment variables.</p>"},{"location":"config/#extended-configurations-in-seasearch","title":"Extended Configurations in SeaSearch","text":""},{"location":"config/#single-node-configurations","title":"Single-Node Configurations","text":"<pre><code>GIN_MODE, log mode of gin framework\uff0cdefault release\nZINC_WAL_ENABLE, whether to enable WAL\uff0cdefaule enabled\nZINC_STORAGE_TYPE\nZINC_MAX_OBJ_CACHE_SIZE, when s3 and oss are enabled, the maximum local cache file size\nZINC_SHARD_LOAD_OBJS_GOROUTINE_NUM, index loading parallelism, when S3 and oss are enabled, can improve the index loading speed\n\nZINC_SHARD_NUM zincsearch the original default value is 3. Since seaseach has one index per database, in order to improve loading efficiency, the default value is changed to 1\n\nS3 related, only valid when ZINC_STORAGE_TYPE=s3\nZINC_S3_ACCESS_ID\nZINC_S3_USE_V4_SIGNATURE\nZINC_S3_ACCESS_SECRET\nZINC_S3_ENDPOINT\nZINC_S3_USE_HTTPS\nZINC_S3_PATH_STYLE_REQUEST\nZINC_S3_AWS_REGION\n\nOSS related, only valid when ZINC_STORAGE_TYPE=oss\nZINC_OSS_ACCESS_ID\nZINC_OSS_ACCESS_SECRET\nZINC_OSS_BUCKET\nZINC_OSS_ENDPOINT\n\ncluster related\nZINC_SERVER_MODE, default none for standalone deployment, optional to cluster, must be cluster for cluster deployment\nZINC_CLUSTER_ID, cluster id\uff0cneed to be globally unique\nZINC_ETCD_ENDPOINTS, etcd address\nZINC_ETCD_ENDPOINTS, etcd key prefix, default /zinc\nZINC_ETCD_USERNAME,  etcd username\nZINC_ETCD_PASSWORD,  etcd password\n\nlog related\nZINC_LOG_OUTPUT, whether to output logs to files, default yes\nZINC_LOG_DIR, log directory, recommended configuration, default is the log subdirectory under the current directory\nZINC_LOG_LEVEL, log level\uff0cdefault debug\n</code></pre>"},{"location":"config/#proxy-configurations","title":"Proxy Configurations","text":"<pre><code>ZINC_CLUSTER_PROXY_LOG_DIR=./log \nZINC_CLUSTER_PROXY_HOST=0.0.0.0\nZINC_CLUSTER_PROXY_PORT=4082\nZINC_SERVER_MODE=proxy # must be proxy\nZINC_ETCD_ENDPOINTS=127.0.0.1:2379\nZINC_ETCD_PREFIX=/zinc\nZINC_MAX_DOCUMENT_SIZE=1m # Bulk and multisearch limit on the maximum single document\uff0cdefault 1m \nZINC_CLUSTER_MANAGER_ADDR=127.0.0.1:4081 # manager address\n</code></pre>"},{"location":"config/#cluster-manger-configurations","title":"Cluster-manger Configurations","text":"<pre><code>ZINC_CLUSTER_MANAGER_LOG_DIR=./log\nZINC_CLUSTER_MANAGER_HOST=0.0.0.0\nZINC_CLUSTER_MANAGER_PORT=4081\nZINC_CLUSTER_MANAGER_ETCD_ENDPOINTS=127.0.0.1:2379\nZINC_CLUSTER_MANAGER_ETCD_PREFIX=/zinc\n</code></pre>"},{"location":"deploy/","title":"Deploy","text":"<p>Note: SeaSearch only supports deployment via docker now.</p>"},{"location":"deploy/#download-the-seasearchyml","title":"Download the seasearch.yml","text":"<pre><code>wget https://haiwen.github.io/seasearch-docs/repo/seasearch.yml\n</code></pre>"},{"location":"deploy/#modify-env-file","title":"Modify .env file","text":"<p>First, you need to specify the environment variables used by the SeaSearch image in the relevant <code>.env</code> file. Some environment variables can be found in here. Please add and modify the values (i.e., <code>&lt;...&gt;</code>) \u200b\u200bof the following fields in the <code>.env</code> file.</p> <pre><code># If seasearch uses a separate configuration file such as seasearch.yml, you need to write it into COMPOSE_FILE\nCOMPOSE_FILE='docker-compose.yml,seasearch.yml'\n\n# other environment variables in .env file\n# For Apple's chip (M2, e.g.), you should use the images with -nomkl tags (i.e., seafileltd/seasearch-nomkl:latest)\nSEASEARCH_IMAGE=seafileltd/seasearch:latest\n\nSEASEARCH_DATA_PATH=&lt;persistent-volume-path-of-seasearch&gt;\nZINC_FIRST_ADMIN_USER=&lt;admin-username&gt;  \nZINC_FIRST_ADMIN_PASSWORD=&lt;admin-password&gt;\n</code></pre> <p>Note: if new environment variables are added in .env, they also need to be set synchronously in the <code>seasearch.yml</code></p>"},{"location":"deploy/#restart-the-service","title":"Restart the Service","text":"<pre><code>docker-compose down\ndocker-compose up\n</code></pre> <p>Browse seasearch services in http://127.0.0.1:4080/.</p>"}]}